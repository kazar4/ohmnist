import tensorflow as tf
import numpy as np
from tensorflow.keras import Model
from tensorflow.python.ops.gen_array_ops import empty
from preprocess import get_data


class Model(tf.keras.Model):
    def __init__(self, num_classes):
        """
        The Model class predicts the next words in a sequence.

        :param vocab_size: The number of unique words in the data
        """

        super(Model, self).__init__()

        # hyperparameters

        self.num_classes = num_classes
        self.batch_size = 25
        self.learning_rate = 1e-3
        self.optimizer = tf.keras.optimizers.Adam(self.learning_rate)

        self.dense1 = tf.keras.layers.Dense(num_classes * num_classes)
        self.dense2 = tf.keras.layers.Dense(num_classes)


    def call(self, inputs):
        """
        take in inputs, output probabilities for each class
        """

        l1out = self.dense1(inputs)
        logits = self.dense2(l1out)

        probs = tf.nn.softmax(logits)

        return probs
        
    def loss(self, probs, labels):
        """
        Calculates average cross entropy sequence to sequence loss of the prediction

        :param probs: calculated probabilities for each class
        :param labels: true class labels for each input
        :return: the loss of the model as a tensor of size 1
        """

        #TODO: Fill in
        #We recommend using tf.keras.losses.sparse_categorical_crossentropy
        #https://www.tensorflow.org/api_docs/python/tf/keras/losses/sparse_categorical_crossentropy

        return tf.reduce_mean(tf.keras.metrics.sparse_categorical_crossentropy(labels, probs))


def train(model, train_inputs, train_labels):
    """
    Runs through one epoch - all training examples.

    :param model: the initilized model to use for forward and backward pass
    :param train_inputs: train inputs (all inputs for training) of shape (num_inputs,)
    :param train_labels: train labels (all labels for training) of shape (num_labels,)
    :return: None
    """
    shuffle = np.arange(len(train_labels))			#reorder for mixed batches
    np.random.shuffle(shuffle)
    tf.gather(train_inputs, shuffle)
    tf.gather(train_labels, shuffle)

    i = 0
    end = int(train_inputs.shape[0])
    while (i + model.batch_size) < end:
        with tf.GradientTape() as g:
            logits = model.call(train_inputs[i:i+model.batch_size])
            loss = model.loss(logits, train_labels[i:i+model.batch_size])
            model.loss_list.append(loss)

        gradients = g.gradient(loss, model.trainable_variables)
        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    
        i += model.batch_size
    
    if not(i == end):
        with tf.GradientTape() as g:
            logits = model.call(train_inputs[i:end])
            loss = model.loss(logits, train_labels[i:end])
            model.loss_list.append(loss)

        gradients = g.gradient(loss, model.trainable_variables)
        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))
    
    return


def test(model, test_inputs, test_labels):
    """
    Runs through one epoch - all testing examples

    :param model: the trained model to use for prediction
    :param test_inputs: train inputs (all inputs for testing) of shape (num_inputs,)
    :param test_labels: train labels (all labels for testing) of shape (num_labels,)
    :returns: list of losses
    """

    losses = []
    i = 0
    end = len(test_inputs)
    while (i + model.batch_size) < end:
        probs = model.call(test_inputs[i:i+model.batch_size])
        losses.append(model.loss(probs, test_labels[i:i+model.batch_size]))
        i += model.batch_size
    
    if not(i == end):
        probs = model.call(test_inputs[i:end])
        losses.append(model.loss(probs, test_labels[i:end]))

    return losses


def main():
    # Pre-process and vectorize the data
    new_dataset = tf.data.experimental.load("./image_outputs/test.db")
    train_data = data[0]
    test_data = data[1]
    # initialize model
    model = Model(12) #12 classes of colors to identify

    #train data needs to be set here TODO

    train(model, train_inputs, train_labels)

    #need to do test data TODO

    # Print out loss 
    print(test(model, test_inputs, test_labels))

    pass

if __name__ == '__main__':
    main()
